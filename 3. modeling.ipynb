{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import copy\n",
    "import hashlib\n",
    "\n",
    "import src.util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = util.load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load train set\n",
    "    x_train = util.pickle_load(params[\"train_feng_set_path\"][0])\n",
    "    y_train = util.pickle_load(params[\"train_feng_set_path\"][1])\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "def load_valid_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load valid set\n",
    "    x_valid = util.pickle_load(params[\"valid_feng_set_path\"][0])\n",
    "    y_valid = util.pickle_load(params[\"valid_feng_set_path\"][1])\n",
    "\n",
    "    return x_valid, y_valid\n",
    "\n",
    "def load_test_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load test set\n",
    "    x_test = util.pickle_load(params[\"test_feng_set_path\"][0])\n",
    "    y_test = util.pickle_load(params[\"test_feng_set_path\"][1])\n",
    "\n",
    "    return x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(params: dict) -> pd.DataFrame:\n",
    "    # Debug message\n",
    "    util.print_debug(\"Loading dataset.\")\n",
    "\n",
    "    # Load train set\n",
    "    x_train, y_train = load_train_feng(params)\n",
    "\n",
    "    # Load valid set\n",
    "    x_valid, y_valid = load_valid_feng(params)\n",
    "\n",
    "    # Load test set\n",
    "    x_test, y_test = load_test_feng(params)\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Dataset loaded.\")\n",
    "\n",
    "    # Return the dataset\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Training Log Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_template() -> dict:\n",
    "    # Debug message\n",
    "    util.print_debug(\"Creating training log template.\")\n",
    "    \n",
    "    # Template of training log\n",
    "    logger = {\n",
    "        \"model_name\" : [],\n",
    "        \"model_uid\" : [],\n",
    "        \"training_time\" : [],\n",
    "        \"training_date\" : [],\n",
    "        \"performance\" : [],\n",
    "        \"f1_score_avg\" : [],\n",
    "        \"data_configurations\" : [],\n",
    "    }\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Training log template created.\")\n",
    "\n",
    "    # Return training log template\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_updater(current_log: dict, params: dict) -> list:\n",
    "    # Create copy of current log\n",
    "    current_log = copy.deepcopy(current_log)\n",
    "\n",
    "    # Path for training log file\n",
    "    log_path = params[\"training_log_path\"]\n",
    "\n",
    "    # Try to load training log file\n",
    "    try:\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "\n",
    "    # If file not found, create a new one\n",
    "    except FileNotFoundError as fe:\n",
    "        with open(log_path, \"w\") as file:\n",
    "            file.write(\"[]\")\n",
    "        file.close()\n",
    "\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "    \n",
    "    # Add current log to previous log\n",
    "    last_log.append(current_log)\n",
    "\n",
    "    # Save updated log\n",
    "    with open(log_path, \"w\") as file:\n",
    "        json.dump(last_log, file)\n",
    "        file.close()\n",
    "\n",
    "    # Return log\n",
    "    return last_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Create Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_object(params: dict) -> list:\n",
    "    # Debug message\n",
    "    util.print_debug(\"Creating model objects.\")\n",
    "\n",
    "    # Create model objects\n",
    "    lgr = LogisticRegression()\n",
    "    dct = DecisionTreeClassifier()\n",
    "    rfc = RandomForestClassifier()\n",
    "    knn = KNeighborsClassifier()\n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    # Create list of model\n",
    "    list_of_model = [\n",
    "        { \"model_name\": lgr.__class__.__name__, \"model_object\": lgr, \"model_uid\": \"\"},\n",
    "        { \"model_name\": dct.__class__.__name__, \"model_object\": dct, \"model_uid\": \"\"},\n",
    "        { \"model_name\": rfc.__class__.__name__, \"model_object\": rfc, \"model_uid\": \"\"},\n",
    "        { \"model_name\": knn.__class__.__name__, \"model_object\": knn, \"model_uid\": \"\"},\n",
    "        { \"model_name\": xgb.__class__.__name__, \"model_object\": xgb, \"model_uid\": \"\"}\n",
    "    ]\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Model objects created.\")\n",
    "\n",
    "    # Return the list of model\n",
    "    return list_of_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Training Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(configuration_model: str, params: dict, hyperparams_model: list = None):\n",
    "    # Load dataset\n",
    "    x_train, y_train, \\\n",
    "    x_valid, y_valid, \\\n",
    "    x_test, y_test = load_dataset(params)\n",
    "\n",
    "    # Variabel to store trained models\n",
    "    list_of_trained_model = dict()\n",
    "\n",
    "    # Create log template\n",
    "    training_log = training_log_template()\n",
    "\n",
    "    # Training for every data configuration\n",
    "    for config_data in x_train:\n",
    "        # Debug message\n",
    "        util.print_debug(\"Training model based on configuration data: {}\".format(config_data))\n",
    "\n",
    "        # Create model objects\n",
    "        if hyperparams_model == None:\n",
    "            list_of_model = create_model_object(params)\n",
    "        else:\n",
    "            list_of_model = copy.deepcopy(hyperparams_model)\n",
    "\n",
    "        # Variabel to store tained model\n",
    "        trained_model = list()\n",
    "\n",
    "        # Load train data based on its configuration\n",
    "        x_train_data = x_train[config_data]\n",
    "        y_train_data = y_train[config_data]\n",
    "\n",
    "        # Train each model by current dataset configuration\n",
    "        for model in list_of_model:\n",
    "            # Debug message\n",
    "            util.print_debug(\"Training model: {}\".format(model[\"model_name\"]))\n",
    "\n",
    "            # Training\n",
    "            training_time = util.time_stamp()\n",
    "            model[\"model_object\"].fit(x_train_data, y_train_data)\n",
    "            training_time = (util.time_stamp() - training_time).total_seconds()\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Evalutaing model: {}\".format(model[\"model_name\"]))\n",
    "\n",
    "            # Evaluation\n",
    "            y_predict = model[\"model_object\"].predict(x_valid)\n",
    "            performance = classification_report(y_valid, y_predict, output_dict = True)\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Logging: {}\".format(model[\"model_name\"]))\n",
    "\n",
    "            # Create UID\n",
    "            uid = hashlib.md5(str(training_time).encode()).hexdigest()\n",
    "\n",
    "            # Assign model's UID\n",
    "            model[\"model_uid\"] = uid\n",
    "\n",
    "            # Create training log data\n",
    "            training_log[\"model_name\"].append(\"{}-{}\".format(configuration_model, model[\"model_name\"]))\n",
    "            training_log[\"model_uid\"].append(uid)\n",
    "            training_log[\"training_time\"].append(training_time)\n",
    "            training_log[\"training_date\"].append(util.time_stamp())\n",
    "            training_log[\"performance\"].append(performance)\n",
    "            training_log[\"f1_score_avg\"].append(performance[\"macro avg\"][\"f1-score\"])\n",
    "            training_log[\"data_configurations\"].append(config_data)\n",
    "\n",
    "            # Collect current trained model\n",
    "            trained_model.append(copy.deepcopy(model))\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Model {} has been trained for configuration data {}.\".format(model[\"model_name\"], config_data))\n",
    "        \n",
    "        # Collect current trained list of model\n",
    "        list_of_trained_model[config_data] = copy.deepcopy(trained_model)\n",
    "    \n",
    "    # Debug message\n",
    "    util.print_debug(\"All combination models and configuration data has been trained.\")\n",
    "    \n",
    "    # Return list trained model\n",
    "    return list_of_trained_model, training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-08 22:32:57.976303 Loading dataset.\n",
      "2022-11-08 22:32:58.024831 Dataset loaded.\n",
      "2022-11-08 22:32:58.024831 Creating training log template.\n",
      "2022-11-08 22:32:58.024831 Training log template created.\n",
      "2022-11-08 22:32:58.024831 Training model based on configuration data: Undersampling\n",
      "2022-11-08 22:32:58.024831 Creating model objects.\n",
      "2022-11-08 22:32:58.024831 Model objects created.\n",
      "2022-11-08 22:32:58.024831 Training model: LogisticRegression\n",
      "2022-11-08 22:32:58.091658 Evalutaing model: LogisticRegression\n",
      "2022-11-08 22:32:58.101197 Logging: LogisticRegression\n",
      "2022-11-08 22:32:58.102197 Model LogisticRegression has been trained for configuration data Undersampling.\n",
      "2022-11-08 22:32:58.102197 Training model: DecisionTreeClassifier\n",
      "2022-11-08 22:32:58.109138 Evalutaing model: DecisionTreeClassifier\n",
      "2022-11-08 22:32:58.115908 Logging: DecisionTreeClassifier\n",
      "2022-11-08 22:32:58.115908 Model DecisionTreeClassifier has been trained for configuration data Undersampling.\n",
      "2022-11-08 22:32:58.115908 Training model: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nvic\\Desktop\\Exercise\\venv_win\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-08 22:32:58.314305 Evalutaing model: RandomForestClassifier\n",
      "2022-11-08 22:32:58.329527 Logging: RandomForestClassifier\n",
      "2022-11-08 22:32:58.341529 Model RandomForestClassifier has been trained for configuration data Undersampling.\n",
      "2022-11-08 22:32:58.341529 Training model: KNeighborsClassifier\n",
      "2022-11-08 22:32:58.344532 Evalutaing model: KNeighborsClassifier\n",
      "2022-11-08 22:32:58.358207 Logging: KNeighborsClassifier\n",
      "2022-11-08 22:32:58.358207 Model KNeighborsClassifier has been trained for configuration data Undersampling.\n",
      "2022-11-08 22:32:58.358207 Training model: XGBClassifier\n",
      "2022-11-08 22:32:59.031262 Evalutaing model: XGBClassifier\n",
      "2022-11-08 22:32:59.037857 Logging: XGBClassifier\n",
      "2022-11-08 22:32:59.041845 Model XGBClassifier has been trained for configuration data Undersampling.\n",
      "2022-11-08 22:32:59.057845 Training model based on configuration data: Oversampling\n",
      "2022-11-08 22:32:59.057845 Creating model objects.\n",
      "2022-11-08 22:32:59.057845 Model objects created.\n",
      "2022-11-08 22:32:59.057845 Training model: LogisticRegression\n",
      "2022-11-08 22:32:59.096929 Evalutaing model: LogisticRegression\n",
      "2022-11-08 22:32:59.100923 Logging: LogisticRegression\n",
      "2022-11-08 22:32:59.100923 Model LogisticRegression has been trained for configuration data Oversampling.\n",
      "2022-11-08 22:32:59.100923 Training model: DecisionTreeClassifier\n",
      "2022-11-08 22:32:59.102922 Evalutaing model: DecisionTreeClassifier\n",
      "2022-11-08 22:32:59.106922 Logging: DecisionTreeClassifier\n",
      "2022-11-08 22:32:59.106922 Model DecisionTreeClassifier has been trained for configuration data Oversampling.\n",
      "2022-11-08 22:32:59.106922 Training model: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nvic\\Desktop\\Exercise\\venv_win\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-08 22:32:59.263312 Evalutaing model: RandomForestClassifier\n",
      "2022-11-08 22:32:59.277312 Logging: RandomForestClassifier\n",
      "2022-11-08 22:32:59.287317 Model RandomForestClassifier has been trained for configuration data Oversampling.\n",
      "2022-11-08 22:32:59.287317 Training model: KNeighborsClassifier\n",
      "2022-11-08 22:32:59.293343 Evalutaing model: KNeighborsClassifier\n",
      "2022-11-08 22:32:59.309464 Logging: KNeighborsClassifier\n",
      "2022-11-08 22:32:59.309464 Model KNeighborsClassifier has been trained for configuration data Oversampling.\n",
      "2022-11-08 22:32:59.309464 Training model: XGBClassifier\n",
      "2022-11-08 22:32:59.363627 Evalutaing model: XGBClassifier\n",
      "2022-11-08 22:32:59.370709 Logging: XGBClassifier\n",
      "2022-11-08 22:32:59.377707 Model XGBClassifier has been trained for configuration data Oversampling.\n",
      "2022-11-08 22:32:59.395791 Training model based on configuration data: SMOTE\n",
      "2022-11-08 22:32:59.395791 Creating model objects.\n",
      "2022-11-08 22:32:59.395791 Model objects created.\n",
      "2022-11-08 22:32:59.395791 Training model: LogisticRegression\n",
      "2022-11-08 22:32:59.434954 Evalutaing model: LogisticRegression\n",
      "2022-11-08 22:32:59.438954 Logging: LogisticRegression\n",
      "2022-11-08 22:32:59.438954 Model LogisticRegression has been trained for configuration data SMOTE.\n",
      "2022-11-08 22:32:59.438954 Training model: DecisionTreeClassifier\n",
      "2022-11-08 22:32:59.442953 Evalutaing model: DecisionTreeClassifier\n",
      "2022-11-08 22:32:59.445953 Logging: DecisionTreeClassifier\n",
      "2022-11-08 22:32:59.445953 Model DecisionTreeClassifier has been trained for configuration data SMOTE.\n",
      "2022-11-08 22:32:59.446953 Training model: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nvic\\Desktop\\Exercise\\venv_win\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-08 22:32:59.647543 Evalutaing model: RandomForestClassifier\n",
      "2022-11-08 22:32:59.662577 Logging: RandomForestClassifier\n",
      "2022-11-08 22:32:59.669544 Model RandomForestClassifier has been trained for configuration data SMOTE.\n",
      "2022-11-08 22:32:59.669544 Training model: KNeighborsClassifier\n",
      "2022-11-08 22:32:59.675542 Evalutaing model: KNeighborsClassifier\n",
      "2022-11-08 22:32:59.689773 Logging: KNeighborsClassifier\n",
      "2022-11-08 22:32:59.689773 Model KNeighborsClassifier has been trained for configuration data SMOTE.\n",
      "2022-11-08 22:32:59.689773 Training model: XGBClassifier\n",
      "2022-11-08 22:32:59.747950 Evalutaing model: XGBClassifier\n",
      "2022-11-08 22:32:59.759947 Logging: XGBClassifier\n",
      "2022-11-08 22:32:59.763948 Model XGBClassifier has been trained for configuration data SMOTE.\n",
      "2022-11-08 22:32:59.782132 All combination models and configuration data has been trained.\n"
     ]
    }
   ],
   "source": [
    "list_of_trained_model, training_log = train_eval(\"Baseline\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Choose Best Performance Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_production_model(list_of_model, training_log, params):\n",
    "    # Create copy list of model\n",
    "    list_of_model = copy.deepcopy(list_of_model)\n",
    "    \n",
    "    # Debug message\n",
    "    util.print_debug(\"Choosing model by metrics score.\")\n",
    "\n",
    "    # Create required predefined variabel\n",
    "    curr_production_model = None\n",
    "    prev_production_model = None\n",
    "    production_model_log = None\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Converting training log type of data from dict to dataframe.\")\n",
    "\n",
    "    # Convert dictionary to pandas for easy operation\n",
    "    training_log = pd.DataFrame(copy.deepcopy(training_log))\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Trying to load previous production model.\")\n",
    "\n",
    "    # Check if there is a previous production model\n",
    "    try:\n",
    "        prev_production_model = util.pickle_load(params[\"production_model_path\"])\n",
    "        util.print_debug(\"Previous production model loaded.\")\n",
    "\n",
    "    except FileNotFoundError as fe:\n",
    "        util.print_debug(\"No previous production model detected, choosing best model only from current trained model.\")\n",
    "\n",
    "    # If previous production model detected:\n",
    "    if prev_production_model != None:\n",
    "        # Debug message\n",
    "        util.print_debug(\"Loading validation data.\")\n",
    "        x_valid, y_valid = load_valid_feng(params)\n",
    "        \n",
    "        # Debug message\n",
    "        util.print_debug(\"Checking compatibilty previous production model's input with current train data's features.\")\n",
    "\n",
    "        # Check list features of previous production model and current dataset\n",
    "        production_model_features = set(prev_production_model[\"model_data\"][\"model_object\"].feature_names_in_)\n",
    "        current_dataset_features = set(x_valid.columns)\n",
    "        number_of_different_features = len((production_model_features - current_dataset_features) | (current_dataset_features - production_model_features))\n",
    "\n",
    "        # If feature matched:\n",
    "        if number_of_different_features == 0:\n",
    "            # Debug message\n",
    "            util.print_debug(\"Features compatible.\")\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Reassesing previous model performance using current validation data.\")\n",
    "\n",
    "            # Re-predict previous production model to provide valid metrics compared to other current models\n",
    "            y_pred = prev_production_model[\"model_data\"][\"model_object\"].predict(x_valid)\n",
    "\n",
    "            # Re-asses prediction result\n",
    "            eval_res = classification_report(y_valid, y_pred, output_dict = True)\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Assessing complete.\")\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Storing new metrics data to previous model structure.\")\n",
    "\n",
    "            # Update their performance log\n",
    "            prev_production_model[\"model_log\"][\"performance\"] = eval_res\n",
    "            prev_production_model[\"model_log\"][\"f1_score_avg\"] = eval_res[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Adding previous model data to current training log and list of model\")\n",
    "\n",
    "            # Added previous production model log to current logs to compere who has the greatest f1 score\n",
    "            training_log = pd.concat([training_log, pd.DataFrame([prev_production_model[\"model_log\"]])])\n",
    "\n",
    "            # Added previous production model to current list of models to choose from if it has the greatest f1 score\n",
    "            list_of_model[\"prev_production_model\"] = [copy.deepcopy(prev_production_model[\"model_data\"])]\n",
    "        else:\n",
    "            # To indicate that we are not using previous production model\n",
    "            prev_production_model = None\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Different features between production model with current dataset is detected, ignoring production dataset.\")\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Sorting training log by f1 macro avg and training time.\")\n",
    "\n",
    "    # Sort training log by f1 score macro avg and trining time\n",
    "    best_model_log = training_log.sort_values([\"f1_score_avg\", \"training_time\"], ascending = [False, True]).iloc[0]\n",
    "    \n",
    "    # Debug message\n",
    "    util.print_debug(\"Searching model data based on sorted training log.\")\n",
    "\n",
    "    # Get model object with greatest f1 score macro avg by using UID\n",
    "    for configuration_data in list_of_model:\n",
    "        for model_data in list_of_model[configuration_data]:\n",
    "            if model_data[\"model_uid\"] == best_model_log[\"model_uid\"]:\n",
    "                curr_production_model = dict()\n",
    "                curr_production_model[\"model_data\"] = copy.deepcopy(model_data)\n",
    "                curr_production_model[\"model_log\"] = copy.deepcopy(best_model_log.to_dict())\n",
    "                curr_production_model[\"model_log\"][\"model_name\"] = \"Production-{}\".format(curr_production_model[\"model_data\"][\"model_name\"])\n",
    "                curr_production_model[\"model_log\"][\"training_date\"] = str(curr_production_model[\"model_log\"][\"training_date\"])\n",
    "                production_model_log = training_log_updater(curr_production_model[\"model_log\"], params)\n",
    "                break\n",
    "    \n",
    "    # In case UID not found\n",
    "    if curr_production_model == None:\n",
    "        raise RuntimeError(\"The best model not found in your list of model.\")\n",
    "    \n",
    "    # Debug message\n",
    "    util.print_debug(\"Model chosen.\")\n",
    "\n",
    "    # Dump chosen production model\n",
    "    util.pickle_dump(curr_production_model, params[\"production_model_path\"])\n",
    "    \n",
    "    # Return current chosen production model, log of production models and current training log\n",
    "    return curr_production_model, production_model_log, training_log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-08 22:34:22.904821 Choosing model by metrics score.\n",
      "2022-11-08 22:34:22.904821 Converting training log type of data from dict to dataframe.\n",
      "2022-11-08 22:34:22.909828 Trying to load previous production model.\n",
      "2022-11-08 22:34:23.002822 Previous production model loaded.\n",
      "2022-11-08 22:34:23.002822 Loading validation data.\n",
      "2022-11-08 22:34:23.004823 Checking compatibilty previous production model's input with current train data's features.\n",
      "2022-11-08 22:34:23.005822 Features compatible.\n",
      "2022-11-08 22:34:23.005822 Reassesing previous model performance using current validation data.\n",
      "2022-11-08 22:34:23.024823 Assessing complete.\n",
      "2022-11-08 22:34:23.024823 Storing new metrics data to previous model structure.\n",
      "2022-11-08 22:34:23.024823 Adding previous model data to current training log and list of model\n",
      "2022-11-08 22:34:23.035856 Sorting training log by f1 macro avg and training time.\n",
      "2022-11-08 22:34:23.041854 Searching model data based on sorted training log.\n",
      "2022-11-08 22:34:23.058822 Model chosen.\n"
     ]
    }
   ],
   "source": [
    "model, production_model_log, training_logs = get_production_model(list_of_trained_model, training_log, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dist_params(model_name: str) -> dict:\n",
    "    # Define models paramteres\n",
    "    dist_params_xgb = {\n",
    "        \"n_estimators\" : [50, 100, 200, 300, 400, 500]\n",
    "    }\n",
    "    dist_params_dct = {\n",
    "        \"algorithm\" : [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        \"min_sample_split\" : [1, 2, 4, 6, 10, 15, 20, 25],\n",
    "        \"min_sample_leaf\" : [1, 2, 4, 6, 10, 15, 20, 25]\n",
    "    }\n",
    "    dist_params_knn = {\n",
    "        \"creterion\" : [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "        \"n_neighbors\" : [2, 3, 4, 5, 6, 10, 15, 20, 25],\n",
    "        \"leaf_size\" : [2, 3, 4, 5, 6, 10, 15, 20, 25],\n",
    "    }\n",
    "    dist_params_lgr = {\n",
    "        \"penalty\" : [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "        \"C\" : [0.01, 0.05, 0.10, 0.15, 0.20, 0.30, 0.60, 0.90, 1],\n",
    "        \"solver\" : [\"saga\"],\n",
    "        \"max_iter\" : [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "    }\n",
    "    dist_params_rfc = {\n",
    "        \"algorithm\" : [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        \"n_estimators\" : [50, 100, 200, 300, 400, 500],\n",
    "        \"min_sample_split\" : [1, 2, 4, 6, 10, 15, 20, 25],\n",
    "        \"min_sample_leaf\" : [1, 2, 4, 6, 10, 15, 20, 25]\n",
    "    }\n",
    "\n",
    "    # Make all models parameters in to one\n",
    "    dist_params = {\n",
    "        \"XGBClassifier\": dist_params_xgb,\n",
    "        \"DecisionTreeClassifier\": dist_params_dct,\n",
    "        \"KNeighborsClassifier\": dist_params_knn,\n",
    "        \"LogisticRegression\": dist_params_lgr,\n",
    "        \"RandomForestClassifier\": dist_params_rfc\n",
    "    }\n",
    "\n",
    "    # Return distribution of model parameters\n",
    "    return dist_params[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_params_tuning(model: dict) -> list:\n",
    "    # Create copy of current best baseline model\n",
    "    model = copy.deepcopy(model)\n",
    "\n",
    "    # Create model's parameter distribution\n",
    "    dist_params = create_dist_params(model[\"model_data\"][\"model_name\"])\n",
    "\n",
    "    # Create model object\n",
    "    model_rsc = RandomizedSearchCV(model[\"model_data\"][\"model_object\"], dist_params, n_jobs = -1)\n",
    "    model_data = {\n",
    "        \"model_name\": model[\"model_data\"][\"model_name\"],\n",
    "        \"model_object\": model_rsc,\n",
    "        \"model_uid\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Return model object\n",
    "    return [model_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-06 20:19:00.417049 Loading dataset.\n",
      "2022-11-06 20:19:00.433047 Dataset loaded.\n",
      "2022-11-06 20:19:00.433047 Creating training log template.\n",
      "2022-11-06 20:19:00.433047 Training log template created.\n",
      "2022-11-06 20:19:00.433047 Training model based on configuration data: Undersampling\n",
      "2022-11-06 20:19:00.438054 Training model: XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nvic\\Desktop\\Exercise\\venv_win\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-06 20:19:09.596445 Evalutaing model: XGBClassifier\n",
      "2022-11-06 20:19:09.609443 Logging: XGBClassifier\n",
      "2022-11-06 20:19:09.624444 Model XGBClassifier has been trained for configuration data Undersampling.\n",
      "2022-11-06 20:19:09.642445 Training model based on configuration data: Oversampling\n",
      "2022-11-06 20:19:09.650444 Training model: XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nvic\\Desktop\\Exercise\\venv_win\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-06 20:19:12.726369 Evalutaing model: XGBClassifier\n",
      "2022-11-06 20:19:12.740369 Logging: XGBClassifier\n",
      "2022-11-06 20:19:12.755370 Model XGBClassifier has been trained for configuration data Oversampling.\n",
      "2022-11-06 20:19:12.769368 Training model based on configuration data: SMOTE\n",
      "2022-11-06 20:19:12.777370 Training model: XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nvic\\Desktop\\Exercise\\venv_win\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-06 20:19:17.122855 Evalutaing model: XGBClassifier\n",
      "2022-11-06 20:19:17.145826 Logging: XGBClassifier\n",
      "2022-11-06 20:19:17.178826 Model XGBClassifier has been trained for configuration data SMOTE.\n",
      "2022-11-06 20:19:17.199825 All combination models and configuration data has been trained.\n"
     ]
    }
   ],
   "source": [
    "list_of_trained_model, training_log = train_eval(\"Hyperparams_Tuning\", params, hyper_params_tuning(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-06 20:19:34.007993 Choosing model by metrics score.\n",
      "2022-11-06 20:19:34.008996 Converting training log type of data from dict to dataframe.\n",
      "2022-11-06 20:19:34.009992 Trying to load previous production model.\n",
      "2022-11-06 20:19:34.021992 Previous production model loaded.\n",
      "2022-11-06 20:19:34.021992 Loading validation data.\n",
      "2022-11-06 20:19:34.024992 Checking compatibilty previous production model's input with current train data's features.\n",
      "2022-11-06 20:19:34.024992 Features compatible.\n",
      "2022-11-06 20:19:34.024992 Reassesing previous model performance using current validation data.\n",
      "2022-11-06 20:19:34.034996 Assessing complete.\n",
      "2022-11-06 20:19:34.034996 Storing new metrics data to previous model structure.\n",
      "2022-11-06 20:19:34.034996 Adding previous model data to current training log and list of model\n",
      "2022-11-06 20:19:34.043994 Sorting training log by f1 macro avg and training time.\n",
      "2022-11-06 20:19:34.045994 Searching model data based on sorted training log.\n",
      "2022-11-06 20:19:34.061995 Model chosen.\n"
     ]
    }
   ],
   "source": [
    "model, production_model_log, training_logs = get_production_model(list_of_trained_model, training_log, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Take a Look at Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = load_valid_feng(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model[\"model_data\"][\"model_object\"].predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2389a8ac5e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6b5ba345f865ccab9c1d1dba86e394ca61d67366183ce7e182371ee31a721f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
